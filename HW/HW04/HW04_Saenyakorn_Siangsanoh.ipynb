{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 Neural Networks\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Answer the questions and upload your answers to courseville. Answers can be\n",
    "in Thai or English. Answers can be either typed or handwritten and scanned.\n",
    "the assignment is divided into several small tasks. Each task is weighted equally\n",
    "(marked with T). For this assignment, each task is awarded equally. There are\n",
    "also optional tasks (marked with OT) counts for half of the required task.\n",
    "\n",
    "## The Basics\n",
    "\n",
    "In this section, we will review some of the basic materials taught in class. These\n",
    "are simple tasks and integral to the understanding of deep neural networks, but\n",
    "many students seem to misunderstand.\n",
    "\n",
    "## T1\n",
    "\n",
    "Compute the forward and backward pass of the following computation.\n",
    "Note that this is a simplified residual connection.\n",
    "\n",
    "\\begin{aligned}\n",
    "  x_1 &= ReLU(x_0 * w_0 + b_0) \\\\\n",
    "  y_1 &= x_1 * w_1 + b_1 \\\\\n",
    "  z &= ReLU(y_1 + x_0)\n",
    "\\end{aligned}\n",
    "\n",
    "Let $x_0 = 1.0, w_0 = 0.3, w_1 = −0.2, b_0 = 0.1, b_1 = −0.3.$ Find the gradient\n",
    "of $z$ with respect to $w_0$, $w_1$, $b_0$, and $b_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "\\begin{aligned}\n",
    "u_0 &= x_0 * w_0 \\\\\n",
    "y_0 &= u_0 + b_0 \\\\\n",
    "x_1 &= ReLU(y_0) \\\\ \\\\\n",
    "\n",
    "u_1 &= x_1 * w_1 \\\\\n",
    "y_1 &= u_1 + b_1 \\\\\n",
    "v_1 &= y_1 + x+0 \\\\\n",
    "z &= ReLU(v_1) \\\\ \\\\\n",
    "\\end{aligned}\n",
    " \n",
    "Forward pass\n",
    "\n",
    "\\begin{aligned}\n",
    "u_0 &= 1.0 * 0.3 = 0.3 \\\\\n",
    "y_0 &= 0.3 + 0.1 = 0.4 \\\\\n",
    "x_1 &= ReLU(0.4) = 0.4 \\\\ \\\\\n",
    "\n",
    "u_1 &= 0.4 * -0.2 = -0.8 \\\\\n",
    "y_1 &= -0.08 + -0.3 = -0.38 \\\\\n",
    "v_1 &= -0.38 + 1.0 = 0.62 \\\\\n",
    "z &= ReLU(0.62) = 0 \\\\ \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "Backward pass\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial z}{\\partial w_0} &= \\frac{\\partial ReLU(v_1)}{\\partial v_1}\\frac{\\partial v_1}{\\partial y_1}\\frac{\\partial y_1}{\\partial u_1}\\frac{\\partial u_1}{\\partial x_1}\\frac{\\partial x_1}{\\partial y_0}\\frac{\\partial y_0}{\\partial u_0}\\frac{\\partial u_0}{\\partial w_0} \\\\\n",
    "&= 1(v_1>0) \\cdot (1) \\cdot (1) \\cdot (w_1) \\cdot 1(y_0>0) \\cdot (1) \\cdot (x_0) \\\\\n",
    "&= -0.2 \\\\ \\\\\n",
    "\n",
    "\\frac{\\partial z}{\\partial w_1} &= \\frac{\\partial ReLU(v_1)}{\\partial v_1}\\frac{\\partial v_1}{\\partial y_1}\\frac{\\partial y_1}{\\partial u_1}\\frac{\\partial u_1}{\\partial w_1} \\\\\n",
    "&= 1(v_1>0) \\cdot (1) \\cdot (1) \\cdot (x_1)  \\\\\n",
    "&= 0.4 \\\\ \\\\\n",
    "\n",
    "\\frac{\\partial z}{\\partial b_0} &= \\frac{\\partial ReLU(v_1)}{\\partial v_1}\\frac{\\partial v_1}{\\partial y_1}\\frac{\\partial y_1}{\\partial u_1}\\frac{\\partial u_1}{\\partial x_1}\\frac{\\partial x_1}{\\partial y_0}\\frac{\\partial y_0}{\\partial b_0} \\\\\n",
    "&= 1(v_1>0) \\cdot (1) \\cdot (1) \\cdot (w_1) \\cdot 1(y_0>0) \\cdot (1) \\\\\n",
    "&= -0.2 \\\\ \\\\\n",
    "\n",
    "\\frac{\\partial z}{\\partial b_1} &= \\frac{\\partial ReLU(v_1)}{\\partial v_1}\\frac{\\partial v_1}{\\partial y_1}\\frac{\\partial y_1}{\\partial b_1} \\\\\n",
    "&= 1(v_1>0) \\cdot (1) \\cdot (1) \\\\\n",
    "&= 1 \\\\ \\\\\n",
    "\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T2\n",
    "\n",
    "Given the following network architecture specifications, determine the size of the output A, B, and C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Output size A: 1024 x 32\n",
    "\n",
    "Output size B: 512 x 32\n",
    "\n",
    "Output size C: 1 x 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T3\n",
    "\n",
    "What is the total number of learnable parameters in this network?\n",
    "(Don’t forget the bias term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "First hidden layer:\n",
    "\n",
    "Learnable parameters = #node + #weight = 1024 + (30 x 1024) = 31744\n",
    "\n",
    "Second hidden layer:\n",
    "\n",
    "Learnable parameters = #node + #weight = 512 + (512 x 1024) = 524800\n",
    "\n",
    "Output: \n",
    "\n",
    "Learnable parameters = #node + #weight = 1 + (1 x 512) = 513\n",
    "\n",
    "Total = 557057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning from (almost) scratch\n",
    "\n",
    "In this section we will code simple a neural network model from scratch (numpy). However, before we go into coding let’s start with some loose ends, namely the gradient of the softmax layer\n",
    "\n",
    "Recall in class we define the softmax layer as:\n",
    "\n",
    "\\begin{aligned}\n",
    "P(y=j) = \\frac{exp(h_j)}{\\Sigma_kexp(h_k)}\n",
    "\\end{aligned}\n",
    "\n",
    "where $h_j$ is the output of the previous layer for class index $j$\n",
    "The cross entropy loss is defined as:\n",
    "\n",
    "\\begin{aligned}\n",
    "L = −\\Sigma_j y_j logP(y = j)\n",
    "\\end{aligned}\n",
    "\n",
    "where $y_j$ is 1 if $y$ is class $j$, and 0 otherwise.\n",
    "\n",
    "## T4. \n",
    "\n",
    "Prove that the derivative of the loss with respect to $h_i$ is $P(y = i) −y_i$. In other words, find $\\frac{∂L}{∂hi}$ for $i ∈ {0, ..., N −1}$ where $N$ is the number of classes.\n",
    "\n",
    "Hint: first find $\\frac{∂P(y=j)}{∂h_i}$ for the case where $j = i$, and the case where $j \\neq i$. Then, use the results with chain rule to find the derivative of the loss.\n",
    "\n",
    "Next, we will code a simple neural network using numpy. Use the starter code **hw4.zip** on github. There are 8 tasks you need to complete in the starter\n",
    "code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "If $i = j$ \n",
    "\n",
    "let $o_j = \\frac{exp(h_j)}{\\Sigma_kexp(h_k)} $\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial o_j}{\\partial h_i} &= \\frac{\\partial \\frac{exp(h_i)}{\\Sigma_kexp(h_k)}}{\\partial h_i} \\\\\n",
    "&= o_i(1 - o_i)\n",
    "\\end{aligned}\n",
    "\n",
    "If $i \\neq j$ \n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial o_j}{\\partial h_i} &= \\frac{\\partial \\frac{exp(h_j)}{\\Sigma_kexp(h_k)}}{\\partial h_i} \\\\\n",
    "&= -o_io_j\n",
    "\\end{aligned}\n",
    "\n",
    "And \n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial o_j} &= \\frac{−\\Sigma_j y_jlog(o_j)}{\\partial o_j} \\\\\n",
    "&= -\\Sigma_j y_j \\frac{log(o_j)}{\\partial o_j} \\\\\n",
    "&= -\\Sigma_j \\frac{y_j}{o_j}\n",
    "\\end{aligned}\n",
    "\n",
    "So if $i=j$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial h_i} &= \\frac{−\\Sigma_i y_jlog(o_i)}{\\partial o_i} \\frac{o_i}{\\partial h_i} \\\\\n",
    "&= -\\Sigma_i \\frac{y_i}{o_i} o_i(1 - o_i) \\\\\n",
    "&= y_io_i - y_i \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "And if $i \\neq j$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial h_i} &= \\frac{−\\Sigma_j y_jlog(o_j)}{\\partial o_j} \\frac{o_j}{\\partial h_i} \\\\\n",
    "&= -\\Sigma_j y_j \\frac{1}{o_j} \\frac{o_j}{\\partial h_i} \\\\\n",
    "&= -y_i(1-o_i) - \\Sigma_{j\\neq i} y_j\\frac{1}{o_j}(-o_jo_i) \\\\\n",
    "&= -y_i + y_ip_i + \\Sigma_{j\\neq i} y_jo_i \\\\\n",
    "&= -y_i + p_i\\Sigma_{j} y_j \\\\\n",
    "&= -y_i + p_i \\\\\n",
    "\\end{aligned}\n",
    " \n",
    "P.S. $\\Sigma_{j} y_j = 1$ since it's one-hot output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
